{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0A6/IcFqmJWKy0sKASlpg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrSimple07/MachineLearning_Practice/blob/main/RandomNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqpFrhMbaS4a",
        "outputId": "dc9dee42-06e9-4f88-fcbd-12d5a5758407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Topic identification\n",
        "\n",
        "import nltk\n",
        "import requests\n",
        "from nltk.corpus import stopwords\n",
        "from gensim import corpora, models\n",
        "from pprint import pprint\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With LDA"
      ],
      "metadata": {
        "id": "DWoeF6Aefgj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random text\n",
        "document = 'It is a very broad definition that can be summed in the following way. The word technology is derived from ‘techne’ and logia, two Greek words.Techne means science. It also stands for the philosophical meaning of using scientific knowledge. Logia means the art of using skills and different  techniques to accomplish a particular motive. After combining both the Greek words, the perfect definition is derived as — The art of using specific  scientific skills and knowledge to accomplish a motive of making an approach better and easier.'\n",
        "\n",
        "stop_words= set(stopwords.words('english'))\n",
        "tokens =[word for word in nltk.word_tokenize(document.lower()) if word.isalpha() and word not in stop_words]\n",
        "\n",
        "\n",
        "dictionary = corpora.Dictionary([tokens])\n",
        "corpus = [dictionary.doc2bow(tokens)]\n",
        "\n",
        "\n",
        "#LDA model - Latent Dirichlet Allocation\n",
        "lda_model = models.LdaModel(corpus, num_topics =1, id2word = dictionary, passes =10)\n",
        "pprint(lda_model.print_topics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrqPmsnRaoS-",
        "outputId": "288f17b5-dcce-4a93-8046-b1de0a71eda1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.047*\"using\" + 0.035*\"knowledge\" + 0.035*\"means\" + 0.035*\"skills\" + '\n",
            "  '0.035*\"scientific\" + 0.035*\"motive\" + 0.035*\"logia\" + 0.035*\"accomplish\" + '\n",
            "  '0.035*\"definition\" + 0.035*\"greek\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP with spaCy\n",
        "\n",
        "- Using for basic text processing and pattern matching\n",
        "- Building machine learning models with text\n",
        "- Representing text with word embeddings"
      ],
      "metadata": {
        "id": "AlxcJQ00jGHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = nlp('The quick brown foxes are jumping over the lazy dogs. They have been running through the fields and forests, exploring the beauty of nature.')"
      ],
      "metadata": {
        "id": "ZWVlo6dAdj6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F3AZg4Vjwk6",
        "outputId": "559980c4-0a29-4abb-c319-89893b7751bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\n",
            "quick\n",
            "brown\n",
            "foxes\n",
            "are\n",
            "jumping\n",
            "over\n",
            "the\n",
            "lazy\n",
            "dogs\n",
            ".\n",
            "They\n",
            "have\n",
            "been\n",
            "running\n",
            "through\n",
            "the\n",
            "fields\n",
            "and\n",
            "forests\n",
            ",\n",
            "exploring\n",
            "the\n",
            "beauty\n",
            "of\n",
            "nature\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatizing and stop words\n",
        "\n",
        "for token in doc:\n",
        "  print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfyZ-g3PjzuL",
        "outputId": "2beb231e-0662-4d35-fde9-77916f595517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\t\tthe\t\tTrue\n",
            "quick\t\tquick\t\tFalse\n",
            "brown\t\tbrown\t\tFalse\n",
            "foxes\t\tfox\t\tFalse\n",
            "are\t\tbe\t\tTrue\n",
            "jumping\t\tjump\t\tFalse\n",
            "over\t\tover\t\tTrue\n",
            "the\t\tthe\t\tTrue\n",
            "lazy\t\tlazy\t\tFalse\n",
            "dogs\t\tdog\t\tFalse\n",
            ".\t\t.\t\tFalse\n",
            "They\t\tthey\t\tTrue\n",
            "have\t\thave\t\tTrue\n",
            "been\t\tbe\t\tTrue\n",
            "running\t\trun\t\tFalse\n",
            "through\t\tthrough\t\tTrue\n",
            "the\t\tthe\t\tTrue\n",
            "fields\t\tfield\t\tFalse\n",
            "and\t\tand\t\tTrue\n",
            "forests\t\tforest\t\tFalse\n",
            ",\t\t,\t\tFalse\n",
            "exploring\t\texplore\t\tFalse\n",
            "the\t\tthe\t\tTrue\n",
            "beauty\t\tbeauty\t\tFalse\n",
            "of\t\tof\t\tTrue\n",
            "nature\t\tnature\t\tFalse\n",
            ".\t\t.\t\tFalse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pattern Matching"
      ],
      "metadata": {
        "id": "c1L-UXmDmK76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "matcher = PhraseMatcher(nlp.vocab, attr ='LOWER')"
      ],
      "metadata": {
        "id": "i9zpawJ4lEBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\n",
        "patterns = [nlp(text) for text in terms]\n",
        "matcher.add(\"TerminologyList\", patterns)"
      ],
      "metadata": {
        "id": "brBgGmcnmDfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n",
        "               \"photography tests pitting the iPhone 11 Pro against the \"\n",
        "               \"Galaxy Note 10 Plus and last year’s iPhone XS and Google Pixel 3.\")\n",
        "matches = matcher(text_doc)\n",
        "print(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0OZnxcWmOgM",
        "outputId": "2f5e6a82-3aa6-4963-f617-039d52a9daa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(3766102292120407359, 17, 19), (3766102292120407359, 22, 24), (3766102292120407359, 30, 32), (3766102292120407359, 33, 35)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_id, start, end = matches[0]\n",
        "print(nlp.vocab.strings[match_id], text_doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yuW_iWfmUmw",
        "outputId": "d9bfc4d1-8716-4d11-d497-e491336ad320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TerminologyList iPhone 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part of Speech (POS) tagging\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYtaUxQHmY9b",
        "outputId": "b66e99df-1355-46f0-8658-cca04f5433d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DET\n",
            "quick ADJ\n",
            "brown ADJ\n",
            "foxes NOUN\n",
            "are AUX\n",
            "jumping VERB\n",
            "over ADP\n",
            "the DET\n",
            "lazy ADJ\n",
            "dogs NOUN\n",
            ". PUNCT\n",
            "They PRON\n",
            "have AUX\n",
            "been AUX\n",
            "running VERB\n",
            "through ADP\n",
            "the DET\n",
            "fields NOUN\n",
            "and CCONJ\n",
            "forests NOUN\n",
            ", PUNCT\n",
            "exploring VERB\n",
            "the DET\n",
            "beauty NOUN\n",
            "of ADP\n",
            "nature NOUN\n",
            ". PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NER\n",
        "for ent in text_doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzfRY0UEoHA0",
        "outputId": "e046be9f-dfd8-414d-88d9-3208f54fc5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Plus and last year DATE\n",
            "iPhone XS ORG\n",
            "Google Pixel ORG\n",
            "3 CARDINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Embeddings\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text, token.vector[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaXjyJlWrimu",
        "outputId": "f723234f-de19-47fe-e324-f695008208e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The [ 0.85183746 -0.29544368  0.6358199   1.5570921  -0.6759108 ]\n",
            "quick [ 0.8100312 -1.2707639  1.0589166  1.1848149  0.2042971]\n",
            "brown [ 0.59353954 -1.1236539   0.06441484  0.52956516  0.09440499]\n",
            "foxes [-0.48174232  0.93088746 -0.5199428   0.48028803  1.6327056 ]\n",
            "are [-0.9376364  -0.8994892  -0.07146559 -0.15708345 -0.4286011 ]\n",
            "jumping [-0.04427019  0.78260726  0.01712537  0.27085647 -1.3030365 ]\n",
            "over [ 0.08426314  0.90991944  0.04415579 -1.2731304  -0.38922563]\n",
            "the [ 1.0078084   1.1961887   0.66080004  1.0293958  -0.02119049]\n",
            "lazy [-0.3079457  -1.1043328   0.40270567  0.05805285 -0.73500675]\n",
            "dogs [-1.020669    1.4565394   0.8399615   0.56590575  0.24345604]\n",
            ". [-0.0751619  -0.62901324 -0.07042383 -1.621114   -0.543389  ]\n",
            "They [-1.6231596  -0.48582357 -0.6938442   0.03227412 -0.39192843]\n",
            "have [-0.32260102 -0.44645384  0.35678056 -0.99264956  0.360287  ]\n",
            "been [-0.21974844 -0.17340861  0.6379559   0.29546565 -1.5078602 ]\n",
            "running [-0.47258344  0.65876794  0.8013135   0.5232028  -0.6259217 ]\n",
            "through [ 0.9440706   1.2979771  -0.30451497 -0.77263975  0.17601797]\n",
            "the [ 1.9075193   0.05665952 -0.10438752  0.4890826  -0.35978764]\n",
            "fields [-1.155302    1.4976478  -0.27144367 -0.18735719  1.2726033 ]\n",
            "and [ 0.4875502  -0.6452007  -1.4982074   0.15568876 -0.09102746]\n",
            "forests [-0.3605336   1.9380891  -0.6962267   0.76329327  2.3596478 ]\n",
            ", [-1.2110195   0.16070631 -0.01924065 -0.87946546 -0.0574486 ]\n",
            "exploring [-1.4187955   0.6713905  -0.5447438   0.30314416  0.520124  ]\n",
            "the [1.4178138  0.41218245 0.22626558 1.0599986  0.08414841]\n",
            "beauty [-0.8724121   0.2925285   0.06854364 -0.8631899   0.5352901 ]\n",
            "of [ 1.1542355  -0.02260794 -1.2703452  -0.66299236 -0.7661575 ]\n",
            "nature [-1.6761302   0.71091956 -0.29541817 -0.7517429   0.6148532 ]\n",
            ". [-0.70964754 -0.38040954  0.2084322  -1.4010756  -0.39970112]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK"
      ],
      "metadata": {
        "id": "DLKA9w4nk0tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "dg1Kdqlwukm8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DaQeKXbm6RF",
        "outputId": "04d12547-2f56-4cd5-bb08-0c1a9358885f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoW and using it for Classification of the text"
      ],
      "metadata": {
        "id": "0dWa2JN1nKfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"I love this product\", \"This is a bad product\", \"I dislike this\", \"This is the best!\"]\n",
        "labels = [1, 0, 0, 1]"
      ],
      "metadata": {
        "id": "3mBWAdRjnAFV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [' '.join(word_tokenize(text)) for text in texts]\n",
        "\n",
        "#BoW vectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(tokens)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(bow, labels, test_size = 0.3, random_state =23)\n",
        "print(bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_zZDoAinIWF",
        "outputId": "cbaa2499-8976-4bc0-8548-fa3b54f46555"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 4)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 5)\t1\n",
            "  (1, 7)\t1\n",
            "  (1, 5)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 0)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 2)\t1\n",
            "  (3, 7)\t1\n",
            "  (3, 3)\t1\n",
            "  (3, 6)\t1\n",
            "  (3, 1)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "predictions = classifier.predict(X_test)\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5niAgBnBoGI-",
        "outputId": "e6470aab-bf26-4335-d557-506d159805c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoW for sentiment analysis"
      ],
      "metadata": {
        "id": "HVmq6f0Fpxub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import movie_reviews\n",
        "import random"
      ],
      "metadata": {
        "id": "H8oJUNZQpOoe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XxcZSsaq8Kb",
        "outputId": "dff93c67-362e-48c2-9946-b0588dd7b99e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "ng7pLcLtq_w0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [''.join(doc) for doc, _ in documents]\n",
        "labels = [1 if category =='pos' else 0 for _, category in documents]"
      ],
      "metadata": {
        "id": "EAfRvzkprXLA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BoW\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(texts)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(bow, labels, test_size =0.3, random_state=23)\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "predictions = classifier.predict(X_test)\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UxxtbkCuR-z",
        "outputId": "bf2fcdf0-d081-427a-9cb4-978ccae40da3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis using NLTK"
      ],
      "metadata": {
        "id": "1oIcGvrBAcR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "tY6voLRKu3sR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3Jbx0JEmJmZ",
        "outputId": "7a19b680-d2fb-4566-e34d-2d6b3217f7ff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "  sid = SentimentIntensityAnalyzer()\n",
        "  sentiment_score =sid.polarity_scores(text)['compound']\n",
        "\n",
        "  print(sentiment_score)\n",
        "\n",
        "\n",
        "  if sentiment_score>=0.05:\n",
        "    return 'Positive'\n",
        "  elif sentiment_score<=-0.05:\n",
        "    return 'Negative'\n",
        "  else:\n",
        "    return 'Neural'\n",
        "\n",
        "text = 'I love NLTK!'\n",
        "result = analyze_sentiment(text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj5gRcaRmNOJ",
        "outputId": "0072fe32-7937-4495-a561-ab37d41f27ca"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6696\n",
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF- IDF (Term Frequency- Inverse Document Frequency) method**\n",
        "\n",
        "Numerical statistic that reflects the importance of a word in a document relative to a collection of documents (corpus)"
      ],
      "metadata": {
        "id": "zic_qgkpeQJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "\n",
        "documents = [\n",
        "    \"Machine learning is the future of technology.\",\n",
        "    \"Natural language processing is a key component of AI.\",\n",
        "    \"Machine learning algorithms analyze large datasets.\",\n",
        "    \"Programming languages play a crucial role in software development.\"\n",
        "]\n",
        "\n",
        "#Create TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "print(tfidf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFwL1U2-ms-l",
        "outputId": "34647045-c4ca-43f3-a082-1f73f26e96f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.42693074 0.         0.3365971  0.         0.\n",
            "  0.         0.         0.3365971  0.3365971  0.         0.3365971\n",
            "  0.         0.         0.         0.         0.         0.42693074\n",
            "  0.42693074]\n",
            " [0.37156534 0.         0.         0.37156534 0.         0.\n",
            "  0.         0.         0.         0.29294639 0.37156534 0.37156534\n",
            "  0.         0.         0.         0.         0.37156534 0.29294639\n",
            "  0.         0.37156534 0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.43671931 0.43671931 0.         0.         0.43671931\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.43671931 0.34431452 0.34431452 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.35355339 0.\n",
            "  0.35355339 0.         0.35355339 0.         0.         0.\n",
            "  0.35355339 0.         0.         0.         0.         0.\n",
            "  0.35355339 0.         0.35355339 0.35355339 0.35355339 0.\n",
            "  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUQ9n15DgHxS",
        "outputId": "24d16042-63fb-4d6f-8a15-c135156cfbc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ai' 'algorithms' 'analyze' 'component' 'crucial' 'datasets'\n",
            " 'development' 'future' 'in' 'is' 'key' 'language' 'languages' 'large'\n",
            " 'learning' 'machine' 'natural' 'of' 'play' 'processing' 'programming'\n",
            " 'role' 'software' 'technology' 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming, Lemmatization, Stow words removal**"
      ],
      "metadata": {
        "id": "DOf3IlnLjaAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1taXArYBgdce",
        "outputId": "9fb5da0f-6e82-40c6-ddad-68014aa4f5b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text):\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "  #Stemming\n",
        "  stemmer = PorterStemmer()\n",
        "  stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "  return{\n",
        "      'original': words,\n",
        "      'stemmed': stemmed_words,\n",
        "      'lemmatized': lemmatized_words\n",
        "  }\n",
        "\n",
        "text = 'The quick brown fox is jumping over the lazy dogs.'\n",
        "\n",
        "preprocessed_data = text_preprocessing(text)\n",
        "print(\"Original words:\", preprocessed_data['original'])\n",
        "print(\"Stemmed words:\", preprocessed_data['stemmed'])\n",
        "print(\"Lemmatized words:\", preprocessed_data['lemmatized'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMEdY9bMkXBr",
        "outputId": "2a4d9d70-a7d0-4bea-f739-5ac78a39a802"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original words: ['quick', 'brown', 'fox', 'jumping', 'lazy', 'dogs', '.']\n",
            "Stemmed words: ['quick', 'brown', 'fox', 'jump', 'lazi', 'dog', '.']\n",
            "Lemmatized words: ['quick', 'brown', 'fox', 'jumping', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "text = 'Some random text for analyzing the context'\n",
        "words = word_tokenize(text)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "lemmatize = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatize.lemmatize(word) for word in words]\n",
        "\n",
        "print(lemmatized_words)\n",
        "\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4--avRjpn7LO",
        "outputId": "8ba5f580-2c86-46fc-99e1-10b088aabb6a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['random', 'text', 'analyzing', 'context']\n",
            "['random', 'text', 'analyz', 'context']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2VEc using Gensim"
      ],
      "metadata": {
        "id": "HCcHa7wM3DVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "corpus = [\n",
        "    \"Word embeddings are cool.\",\n",
        "    \"They help machines understand language.\",\n",
        "    \"Word2Vec is a popular technique for creating embeddings.\",\n",
        "    \"NLTK is a powerful natural language processing library.\"\n",
        "]\n",
        "\n",
        "tokenized_corpus = [word_tokenize(sent.lower()) for sent in sent_tokenize(\" \".join(corpus))]\n",
        "\n",
        "word2vec_model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
        "word2vec_model.save(\"word2vec_model.bin\")\n",
        "\n",
        "similar_words = word2vec_model.wv.most_similar('word', topn=3)\n",
        "print(f\"Words similar to 'word': {similar_words}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zP_tyXK0w-j",
        "outputId": "480d8346-b168-47c5-b955-ba746b98cc5f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'word': [('word2vec', 0.14901481568813324), ('is', 0.09936431050300598), ('are', 0.09429703652858734)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK datasets for text classification, topic classification and sentiment analysis**\n",
        "\n",
        "1. Reuters Corpus\n",
        "2. 20 NewsGroups\n",
        "3. IMDB Review - Positive, negative\n",
        "4. Brown Corpus\n",
        "5. Webtext Corpus"
      ],
      "metadata": {
        "id": "eojimPxhqKhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We will use reuters Corpus\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "nltk.download('reuters')\n",
        "corpus = nltk.corpus.reuters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV1F8m2F3UoD",
        "outputId": "184f3ce8-08b3-4ee3-f8df-e9c48d295d89"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = corpus.categories()\n",
        "fileids = corpus.fileids()"
      ],
      "metadata": {
        "id": "HxLd1T37rqi7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(categories))\n",
        "print(len(fileids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUvFZ3WUs5Yk",
        "outputId": "10abc1bc-c4af-4d13-f385-e109d1c0f133"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n",
            "10788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataframe\n",
        "\n",
        "documents = []\n",
        "for fileid in fileids:\n",
        "  category = corpus.categories(fileid)[0]\n",
        "  raw_text = corpus.raw(fileid)\n",
        "  documents.append({'fileid': fileid, 'category': category, 'text': raw_text})\n",
        "\n",
        "df = pd.DataFrame(documents)\n"
      ],
      "metadata": {
        "id": "5z93IgXptplv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "tDI2KQL4uNWL",
        "outputId": "094da9ed-90cc-4c03-bacc-6bfcff5e3fce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       fileid  category                                               text\n",
              "0  test/14826     trade  ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...\n",
              "1  test/14828     grain  CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...\n",
              "2  test/14829     crude  JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...\n",
              "3  test/14832      corn  THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...\n",
              "4  test/14833  palm-oil  INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d105b82-cabe-4bb3-b49f-0568c0e94720\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fileid</th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test/14826</td>\n",
              "      <td>trade</td>\n",
              "      <td>ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test/14828</td>\n",
              "      <td>grain</td>\n",
              "      <td>CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test/14829</td>\n",
              "      <td>crude</td>\n",
              "      <td>JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test/14832</td>\n",
              "      <td>corn</td>\n",
              "      <td>THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test/14833</td>\n",
              "      <td>palm-oil</td>\n",
              "      <td>INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d105b82-cabe-4bb3-b49f-0568c0e94720')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d105b82-cabe-4bb3-b49f-0568c0e94720 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d105b82-cabe-4bb3-b49f-0568c0e94720');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-51b24d86-c2c7-488f-ba7d-98b7b8a80913\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51b24d86-c2c7-488f-ba7d-98b7b8a80913')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-51b24d86-c2c7-488f-ba7d-98b7b8a80913 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(df.loc[1, 'text'].split())\n",
        "print(num_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dya6r7zluY_Y",
        "outputId": "03cfd198-a810-4e01-b5fd-f30626a11f9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[[1]]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "FSGMDmHlvQXO",
        "outputId": "516490a3-c568-437b-f021-2b3791e85967"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       fileid category                                               text\n",
              "1  test/14828    grain  CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3081a79d-93cf-4e8e-8d5b-4a855952dfa9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fileid</th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test/14828</td>\n",
              "      <td>grain</td>\n",
              "      <td>CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3081a79d-93cf-4e8e-8d5b-4a855952dfa9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3081a79d-93cf-4e8e-8d5b-4a855952dfa9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3081a79d-93cf-4e8e-8d5b-4a855952dfa9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWemxDH-va6b",
        "outputId": "8a967116-6078-4ec0-d54c-94b1f33c8047"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text processing\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('owm-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtPQc5lyvcM5",
        "outputId": "30e1a429-15c8-4512-92d1-7ed8f133ea34"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Error loading owm-1.4: Package 'owm-1.4' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "gc17uytSvghc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "  text = text.lower()\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  import string\n",
        "  words = [token for token in words if token not in string.punctuation]\n",
        "  words = [token for token in words if token not in stop_words]\n",
        "\n",
        "  words = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "  expanded_terms = {\n",
        "    'pct': 'percentage',\n",
        "    'mln':'million'\n",
        "    }\n",
        "\n",
        "  words = [expanded_terms.get(word, word) for word in words]\n",
        "\n",
        "  preprocessed_text = ' '.join(words)\n",
        "\n",
        "  return preprocessed_text"
      ],
      "metadata": {
        "id": "Ff_hiP3iwW97"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "S0hnxYHVxkpN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.clean_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsQHdQdixnSF",
        "outputId": "1ccfa5af-ca61-411f-8436-56f8cbb7c5ae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    china daily say vermin eat 7-12 percentage gra...\n",
              "Name: clean_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Recurrent Neural network using keras for sequence analysis tasks**"
      ],
      "metadata": {
        "id": "2-Qaw5x_ACs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer"
      ],
      "metadata": {
        "id": "LBTDFdrB0wYL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [\n",
        "    'This is a positive sequence.',\n",
        "    'This is a negative sequence.',\n",
        "    'Another positive example.',\n",
        "    'Not a good one.'\n",
        "]\n",
        "labels = [1, 0, 1, 0]  # 1 for positive, 0 for negative\n",
        "\n",
        "sequences = [str(seq) for seq in sequences]"
      ],
      "metadata": {
        "id": "eOWvy5DRBton"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "vocab_size = len(tokenizer.word_index) +1\n",
        "sequences = tokenizer.texts_to_sequences(sequences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7Ykq7rvBv26",
        "outputId": "dc6f80cd-3759-4a6d-8ecc-0e0b7581b19a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3, 1, 4, 5], [2, 3, 1, 6, 5], [7, 4, 8], [9, 1, 10, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to ensure equal length\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "JtL32GyzB_2g"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple RNN model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = vocab_size, output_dim = 8, input_length = max_length))\n",
        "model.add(SimpleRNN(16)) #SimpleRNN layer with 16 units\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(optimizer ='adam', loss ='binary_crossentropy', metrics =['accuracy'])\n",
        "\n",
        "model.fit(padded_sequences, labels, epochs =10, verbose =1)\n",
        "\n",
        "new_sequence = ['A positive example.']\n",
        "new_sequence = tokenizer.texts_to_sequences(new_sequence)\n",
        "new_padded_sequence = pad_sequences(new_sequence, maxlen=max_length, padding='post')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(new_padded_sequence)\n",
        "print(f'Predicted Probability: {predictions[0, 0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn4FDOMJC3cI",
        "outputId": "2d799137-adc5-4ec9-a24c-8d915985c475"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6837 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6796 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6755 - accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6714 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6673 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6630 - accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6587 - accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6543 - accuracy: 0.7500\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6497 - accuracy: 0.7500\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6450 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "Predicted Probability: 0.5513021945953369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oAFXOy4MDgDO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}