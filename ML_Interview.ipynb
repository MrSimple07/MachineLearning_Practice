{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoRaZkNAyTH4x4IVxe0j7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrSimple07/MachineLearning_Practice/blob/main/ML_Interview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is Multilayer Perceptron (MLP) and Boltzmann Machine?**\n",
        "*   MLP - one input, more hidden layers and one output\n",
        "* Feedforward Architecture. Information flows the network in one direction\n",
        "* MLPs are widely used for various tasks, including classification, regression, and pattern recognition.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "  - Boltzman Machine is a simplified version of the MLP.\n",
        "  - 2 layer model with a visible input layer and a hidden layer which makes stocastic decision\n",
        "  - Boltzmann Machines and RBMs have been applied to various tasks, including dimensionality reduction, collaborative filtering, and feature learning."
      ],
      "metadata": {
        "id": "LNqGUVwHX2Cu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C2Kj55PXxmf",
        "outputId": "e48c736e-1199-4629-bafe-1ab257d7861a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3/3 - 2s - loss: 1.3126 - accuracy: 0.3333 - val_loss: 1.1770 - val_accuracy: 0.3333 - 2s/epoch - 690ms/step\n",
            "Epoch 2/50\n",
            "3/3 - 0s - loss: 1.2410 - accuracy: 0.3542 - val_loss: 1.1230 - val_accuracy: 0.3333 - 133ms/epoch - 44ms/step\n",
            "Epoch 3/50\n",
            "3/3 - 0s - loss: 1.1756 - accuracy: 0.4062 - val_loss: 1.0703 - val_accuracy: 0.4583 - 114ms/epoch - 38ms/step\n",
            "Epoch 4/50\n",
            "3/3 - 0s - loss: 1.1094 - accuracy: 0.4062 - val_loss: 1.0205 - val_accuracy: 0.5417 - 125ms/epoch - 42ms/step\n",
            "Epoch 5/50\n",
            "3/3 - 0s - loss: 1.0472 - accuracy: 0.4167 - val_loss: 0.9738 - val_accuracy: 0.5417 - 259ms/epoch - 86ms/step\n",
            "Epoch 6/50\n",
            "3/3 - 0s - loss: 0.9937 - accuracy: 0.4583 - val_loss: 0.9293 - val_accuracy: 0.6667 - 74ms/epoch - 25ms/step\n",
            "Epoch 7/50\n",
            "3/3 - 0s - loss: 0.9403 - accuracy: 0.6562 - val_loss: 0.8886 - val_accuracy: 0.8333 - 89ms/epoch - 30ms/step\n",
            "Epoch 8/50\n",
            "3/3 - 0s - loss: 0.8908 - accuracy: 0.7708 - val_loss: 0.8507 - val_accuracy: 0.8750 - 90ms/epoch - 30ms/step\n",
            "Epoch 9/50\n",
            "3/3 - 0s - loss: 0.8466 - accuracy: 0.7604 - val_loss: 0.8158 - val_accuracy: 0.8750 - 145ms/epoch - 48ms/step\n",
            "Epoch 10/50\n",
            "3/3 - 0s - loss: 0.8075 - accuracy: 0.7604 - val_loss: 0.7834 - val_accuracy: 0.8333 - 107ms/epoch - 36ms/step\n",
            "Epoch 11/50\n",
            "3/3 - 0s - loss: 0.7690 - accuracy: 0.7500 - val_loss: 0.7539 - val_accuracy: 0.8333 - 79ms/epoch - 26ms/step\n",
            "Epoch 12/50\n",
            "3/3 - 0s - loss: 0.7362 - accuracy: 0.7604 - val_loss: 0.7274 - val_accuracy: 0.8333 - 179ms/epoch - 60ms/step\n",
            "Epoch 13/50\n",
            "3/3 - 0s - loss: 0.7067 - accuracy: 0.7604 - val_loss: 0.7030 - val_accuracy: 0.8333 - 83ms/epoch - 28ms/step\n",
            "Epoch 14/50\n",
            "3/3 - 0s - loss: 0.6797 - accuracy: 0.7604 - val_loss: 0.6813 - val_accuracy: 0.8333 - 103ms/epoch - 34ms/step\n",
            "Epoch 15/50\n",
            "3/3 - 0s - loss: 0.6559 - accuracy: 0.7604 - val_loss: 0.6607 - val_accuracy: 0.8333 - 90ms/epoch - 30ms/step\n",
            "Epoch 16/50\n",
            "3/3 - 0s - loss: 0.6340 - accuracy: 0.7604 - val_loss: 0.6422 - val_accuracy: 0.8333 - 248ms/epoch - 83ms/step\n",
            "Epoch 17/50\n",
            "3/3 - 0s - loss: 0.6150 - accuracy: 0.7604 - val_loss: 0.6249 - val_accuracy: 0.8333 - 165ms/epoch - 55ms/step\n",
            "Epoch 18/50\n",
            "3/3 - 0s - loss: 0.5971 - accuracy: 0.7917 - val_loss: 0.6088 - val_accuracy: 0.8333 - 143ms/epoch - 48ms/step\n",
            "Epoch 19/50\n",
            "3/3 - 0s - loss: 0.5813 - accuracy: 0.7917 - val_loss: 0.5937 - val_accuracy: 0.8333 - 102ms/epoch - 34ms/step\n",
            "Epoch 20/50\n",
            "3/3 - 0s - loss: 0.5667 - accuracy: 0.7917 - val_loss: 0.5800 - val_accuracy: 0.8333 - 125ms/epoch - 42ms/step\n",
            "Epoch 21/50\n",
            "3/3 - 0s - loss: 0.5534 - accuracy: 0.7917 - val_loss: 0.5671 - val_accuracy: 0.8333 - 179ms/epoch - 60ms/step\n",
            "Epoch 22/50\n",
            "3/3 - 0s - loss: 0.5412 - accuracy: 0.7917 - val_loss: 0.5553 - val_accuracy: 0.8333 - 94ms/epoch - 31ms/step\n",
            "Epoch 23/50\n",
            "3/3 - 0s - loss: 0.5298 - accuracy: 0.7917 - val_loss: 0.5439 - val_accuracy: 0.8333 - 116ms/epoch - 39ms/step\n",
            "Epoch 24/50\n",
            "3/3 - 0s - loss: 0.5190 - accuracy: 0.7917 - val_loss: 0.5336 - val_accuracy: 0.8333 - 91ms/epoch - 30ms/step\n",
            "Epoch 25/50\n",
            "3/3 - 0s - loss: 0.5093 - accuracy: 0.7917 - val_loss: 0.5237 - val_accuracy: 0.8333 - 79ms/epoch - 26ms/step\n",
            "Epoch 26/50\n",
            "3/3 - 0s - loss: 0.5001 - accuracy: 0.7917 - val_loss: 0.5141 - val_accuracy: 0.8333 - 92ms/epoch - 31ms/step\n",
            "Epoch 27/50\n",
            "3/3 - 0s - loss: 0.4914 - accuracy: 0.7917 - val_loss: 0.5051 - val_accuracy: 0.8333 - 158ms/epoch - 53ms/step\n",
            "Epoch 28/50\n",
            "3/3 - 0s - loss: 0.4830 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.8333 - 188ms/epoch - 63ms/step\n",
            "Epoch 29/50\n",
            "3/3 - 0s - loss: 0.4752 - accuracy: 0.7917 - val_loss: 0.4896 - val_accuracy: 0.8333 - 102ms/epoch - 34ms/step\n",
            "Epoch 30/50\n",
            "3/3 - 0s - loss: 0.4680 - accuracy: 0.7917 - val_loss: 0.4823 - val_accuracy: 0.8333 - 80ms/epoch - 27ms/step\n",
            "Epoch 31/50\n",
            "3/3 - 0s - loss: 0.4609 - accuracy: 0.7917 - val_loss: 0.4754 - val_accuracy: 0.8333 - 77ms/epoch - 26ms/step\n",
            "Epoch 32/50\n",
            "3/3 - 0s - loss: 0.4541 - accuracy: 0.8021 - val_loss: 0.4683 - val_accuracy: 0.8333 - 89ms/epoch - 30ms/step\n",
            "Epoch 33/50\n",
            "3/3 - 0s - loss: 0.4477 - accuracy: 0.8021 - val_loss: 0.4616 - val_accuracy: 0.8333 - 132ms/epoch - 44ms/step\n",
            "Epoch 34/50\n",
            "3/3 - 0s - loss: 0.4412 - accuracy: 0.8021 - val_loss: 0.4555 - val_accuracy: 0.8750 - 162ms/epoch - 54ms/step\n",
            "Epoch 35/50\n",
            "3/3 - 0s - loss: 0.4353 - accuracy: 0.8021 - val_loss: 0.4494 - val_accuracy: 0.8750 - 135ms/epoch - 45ms/step\n",
            "Epoch 36/50\n",
            "3/3 - 0s - loss: 0.4296 - accuracy: 0.8229 - val_loss: 0.4438 - val_accuracy: 0.8750 - 93ms/epoch - 31ms/step\n",
            "Epoch 37/50\n",
            "3/3 - 0s - loss: 0.4242 - accuracy: 0.8229 - val_loss: 0.4386 - val_accuracy: 0.8750 - 77ms/epoch - 26ms/step\n",
            "Epoch 38/50\n",
            "3/3 - 0s - loss: 0.4187 - accuracy: 0.8229 - val_loss: 0.4329 - val_accuracy: 0.8750 - 69ms/epoch - 23ms/step\n",
            "Epoch 39/50\n",
            "3/3 - 0s - loss: 0.4136 - accuracy: 0.8229 - val_loss: 0.4279 - val_accuracy: 0.9167 - 73ms/epoch - 24ms/step\n",
            "Epoch 40/50\n",
            "3/3 - 0s - loss: 0.4084 - accuracy: 0.8229 - val_loss: 0.4229 - val_accuracy: 0.9167 - 119ms/epoch - 40ms/step\n",
            "Epoch 41/50\n",
            "3/3 - 0s - loss: 0.4034 - accuracy: 0.8333 - val_loss: 0.4186 - val_accuracy: 0.9167 - 96ms/epoch - 32ms/step\n",
            "Epoch 42/50\n",
            "3/3 - 0s - loss: 0.3987 - accuracy: 0.8333 - val_loss: 0.4136 - val_accuracy: 0.9167 - 162ms/epoch - 54ms/step\n",
            "Epoch 43/50\n",
            "3/3 - 0s - loss: 0.3940 - accuracy: 0.8333 - val_loss: 0.4090 - val_accuracy: 0.9167 - 144ms/epoch - 48ms/step\n",
            "Epoch 44/50\n",
            "3/3 - 0s - loss: 0.3894 - accuracy: 0.8333 - val_loss: 0.4048 - val_accuracy: 0.9167 - 130ms/epoch - 43ms/step\n",
            "Epoch 45/50\n",
            "3/3 - 0s - loss: 0.3849 - accuracy: 0.8333 - val_loss: 0.4005 - val_accuracy: 0.9167 - 146ms/epoch - 49ms/step\n",
            "Epoch 46/50\n",
            "3/3 - 0s - loss: 0.3807 - accuracy: 0.8333 - val_loss: 0.3960 - val_accuracy: 0.9167 - 164ms/epoch - 55ms/step\n",
            "Epoch 47/50\n",
            "3/3 - 0s - loss: 0.3763 - accuracy: 0.8333 - val_loss: 0.3920 - val_accuracy: 0.9167 - 111ms/epoch - 37ms/step\n",
            "Epoch 48/50\n",
            "3/3 - 0s - loss: 0.3720 - accuracy: 0.8333 - val_loss: 0.3883 - val_accuracy: 0.9167 - 126ms/epoch - 42ms/step\n",
            "Epoch 49/50\n",
            "3/3 - 0s - loss: 0.3681 - accuracy: 0.8333 - val_loss: 0.3846 - val_accuracy: 0.9167 - 135ms/epoch - 45ms/step\n",
            "Epoch 50/50\n",
            "3/3 - 0s - loss: 0.3638 - accuracy: 0.8438 - val_loss: 0.3807 - val_accuracy: 0.9167 - 161ms/epoch - 54ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "Predicted Classes for New Data: 8\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X,y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "# Build the MLP model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=2)\n",
        "\n",
        "\n",
        "\n",
        "prob = model.predict(X_test)\n",
        "\n",
        "y_pred = np.argmax(prob)\n",
        "\n",
        "# Evaluate the performance\n",
        "print(\"Predicted Classes for New Data:\", y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. How can we relate standard deviation and variance?**\n",
        "- Standard Deviation = square root of Variance\n",
        "- St. deviation refers to the spread of the data from the mean.\n",
        "- Variance is the average degree of all data points"
      ],
      "metadata": {
        "id": "mYegEZvNjrXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data =np.array([1,3,5,7,4,3,2])\n",
        "\n",
        "variance= np.var(data)\n",
        "std_deviation = np.sqrt(variance)\n",
        "\n",
        "print(variance)\n",
        "print(std_deviation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGygEQrpaiTH",
        "outputId": "63be9d8f-17cc-4332-ba2f-c0a111705502"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3877551020408165\n",
            "1.8405855323893037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. The Empiric Rule: 68- 95-99.7 or the three-sigma rule**\n",
        "1. About 68% of the data falls within one standard deviation from the mean.\n",
        "\n",
        "2. About 95% of the data falls within two standard deviations from the mean.\n",
        "\n",
        "3. About 99.7% of the data falls within three standard deviations from the mean.\n",
        "\n",
        "These rules are useful for understanding the distribution of data and identifying potential outliers. They are based on the assumption of a normal distribution."
      ],
      "metadata": {
        "id": "-ZlJSnEqllCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Is a high variance in data good or bad? And how to handle it?\n",
        "- Higher variance means the data spread is big and the features has a variety of data. It is usually bad.\n",
        "- To handle high variance we can use, bagging algorithm\n",
        "- Bagging algorithm splits the data intosubgroups with sampling replicated from random data"
      ],
      "metadata": {
        "id": "6XZGFficmYRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "3."
      ],
      "metadata": {
        "id": "NhRYaTuflFTb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}