{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG+r3W5MhLOKMPflAK8i50",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrSimple07/MachineLearning_Practice/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic PyTorch\n",
        "\n",
        "Pytorch is a open source deep learning framework for python, developed by Facebook's AI research lab. It is a library for processing tensors.\n",
        "- Tensor is multidimensional arrays\n",
        "- Numpy=> arrays, pytorch => tensors\n",
        "- It is popular for faster processing by GPU's. Especially for Deep learning"
      ],
      "metadata": {
        "id": "AYcNSb7ZVLuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKmxZJMvSuP9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Generate synthetic data\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1)\n",
        "y = 2 * X + 1 + 0.1 * np.random.randn(100, 1)\n",
        "\n",
        "# Step 2: Convert data to PyTorch tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "# Step 3: Define a simple linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # One input feature, one output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Step 4: Instantiate the model, loss function, and optimizer\n",
        "model = LinearRegressionModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Step 5: Training the model\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_tensor)\n",
        "    loss = criterion(outputs, y_tensor)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Step 6: Plot the results\n",
        "predicted = model(X_tensor).detach().numpy()\n",
        "\n",
        "plt.scatter(X, y, label='Original data')\n",
        "plt.plot(X, predicted, label='Fitted line', color='red')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "e-4V5KTMVWxk",
        "outputId": "22f21df2-06b6-4b79-979e-af08c9d7dd64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.1796\n",
            "Epoch [200/1000], Loss: 0.0960\n",
            "Epoch [300/1000], Loss: 0.0740\n",
            "Epoch [400/1000], Loss: 0.0577\n",
            "Epoch [500/1000], Loss: 0.0455\n",
            "Epoch [600/1000], Loss: 0.0363\n",
            "Epoch [700/1000], Loss: 0.0293\n",
            "Epoch [800/1000], Loss: 0.0241\n",
            "Epoch [900/1000], Loss: 0.0201\n",
            "Epoch [1000/1000], Loss: 0.0171\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers, models, datasets\n",
        "from keras.models import Sequential\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    layers.Flatten(input_shape = (28,28)),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs = 5, validation_data = (test_images, test_labels))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "6fqkoFERW7s7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf50048c-cbfa-476c-e3ee-ae0e34b2d31d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2935 - accuracy: 0.9150 - val_loss: 0.1409 - val_accuracy: 0.9600\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1409 - accuracy: 0.9572 - val_loss: 0.0974 - val_accuracy: 0.9697\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1058 - accuracy: 0.9680 - val_loss: 0.0847 - val_accuracy: 0.9745\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0866 - accuracy: 0.9726 - val_loss: 0.0756 - val_accuracy: 0.9762\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0731 - accuracy: 0.9771 - val_loss: 0.0774 - val_accuracy: 0.9764\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.9764\n",
            "0.9764000177383423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "model = Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation  = 'relu'),\n",
        "    layers.Dense(10, activation ='relu')\n",
        "])\n",
        "\n",
        "model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs = 5, batch_size = 64, validation_data = (test_images, test_labels))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AeQKO8E-lRx",
        "outputId": "7b38eb15-3720-478b-cb3b-1fcf8bb966e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 53s 55ms/step - loss: 2.2285 - accuracy: 0.1508 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 50s 53ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 49s 52ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 50s 53ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 50s 53ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.3026 - accuracy: 0.0980\n",
            "0.09799999743700027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout, Activation\n",
        "from keras.layers import GlobalMaxPooling2D"
      ],
      "metadata": {
        "id": "BYdmxphyA4dI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "data_augmentation = True"
      ],
      "metadata": {
        "id": "6FyJKrTjE_YO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNFt95jsFEN8",
        "outputId": "b6f031ef-d956-4226-a1f7-7539f6df19b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(48, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(80, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(GlobalMaxPooling2D())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(500))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3jzvBm-FQB5",
        "outputId": "569a1552-9177-48de-9a23-b7e7a157cb79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 48)        13872     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 32, 32, 48)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 16, 16, 48)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16, 16, 48)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 80)        34640     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 16, 16, 80)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 8, 8, 80)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 8, 8, 80)          0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 128)         92288     \n",
            "                                                                 \n",
            " global_max_pooling2d_2 (Gl  (None, 128)               0         \n",
            " obalMaxPooling2D)                                               \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 500)               64500     \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 500)               0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 500)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                5010      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 211206 (825.02 KB)\n",
            "Trainable params: 211206 (825.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph2', histogram_freq=0, write_graph=True, write_images=True)"
      ],
      "metadata": {
        "id": "tWlf3e3zFsT6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True, callbacks=[tbCallBack])\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    '''\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "    '''\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test), callbacks=[tbCallBack])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pwARgb7F4cr",
        "outputId": "47b9b6f5-33e2-4829-8494-edc33cd78529"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-c0aa93279554>:42: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(x_train, y_train,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1562/1562 [==============================] - 304s 193ms/step - loss: 1.7147 - accuracy: 0.3613 - val_loss: 1.2841 - val_accuracy: 0.5252\n",
            "Epoch 2/10\n",
            "1562/1562 [==============================] - 311s 199ms/step - loss: 1.3535 - accuracy: 0.5079 - val_loss: 1.1259 - val_accuracy: 0.5956\n",
            "Epoch 3/10\n",
            "1562/1562 [==============================] - 306s 196ms/step - loss: 1.2149 - accuracy: 0.5640 - val_loss: 0.9904 - val_accuracy: 0.6407\n",
            "Epoch 4/10\n",
            "1562/1562 [==============================] - 298s 191ms/step - loss: 1.1415 - accuracy: 0.5919 - val_loss: 1.1239 - val_accuracy: 0.6060\n",
            "Epoch 5/10\n",
            "1562/1562 [==============================] - 309s 198ms/step - loss: 1.0951 - accuracy: 0.6098 - val_loss: 0.8507 - val_accuracy: 0.6979\n",
            "Epoch 6/10\n",
            "1562/1562 [==============================] - 310s 199ms/step - loss: 1.0490 - accuracy: 0.6303 - val_loss: 0.8917 - val_accuracy: 0.6822\n",
            "Epoch 7/10\n",
            "1562/1562 [==============================] - 300s 192ms/step - loss: 1.0282 - accuracy: 0.6377 - val_loss: 0.8551 - val_accuracy: 0.6933\n",
            "Epoch 8/10\n",
            "1562/1562 [==============================] - 301s 193ms/step - loss: 1.0025 - accuracy: 0.6452 - val_loss: 1.0362 - val_accuracy: 0.6417\n",
            "Epoch 9/10\n",
            "1562/1562 [==============================] - 300s 192ms/step - loss: 0.9829 - accuracy: 0.6544 - val_loss: 0.8755 - val_accuracy: 0.6973\n",
            "Epoch 10/10\n",
            "1562/1562 [==============================] - 302s 193ms/step - loss: 0.9684 - accuracy: 0.6585 - val_loss: 0.7837 - val_accuracy: 0.7304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative Adversial Network (GAN) for generating images of MNIST using Streamlit"
      ],
      "metadata": {
        "id": "5fqEQV9IJNOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVdpYOZNHwKi",
        "outputId": "a20b0d18-c679-45b2-8ad2-fb610751a76d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.30.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<8,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (7.0.1)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.41 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.30.0 validators-0.22.0 watchdog-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization\n",
        "from keras.layers import Reshape, Flatten, Conv2DTranspose, Input\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "B07xUnSdGEse"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, _), (_, _) = mnist.load_data()\n",
        "X_train = X_train / 127.5 - 1.0\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "def build_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128 * 7 * 7, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh'))\n",
        "    return model\n",
        "\n",
        "# Build discriminator model\n",
        "def build_discriminator(input_shape=(28, 28, 1)):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnS4QKZuHqBz",
        "outputId": "b889147e-942f-466a-e89e-fd31b233037c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
        "\n",
        "latent_dim = 100\n",
        "generator = build_generator(latent_dim)\n",
        "z = Input(shape=(latent_dim,))\n",
        "img = generator(z)\n",
        "discriminator.trainable = False\n",
        "validity = discriminator(img)\n",
        "combined = Model(z, validity)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
        "\n",
        "\n",
        "def train(epochs, batch_size=128, save_interval=50):\n",
        "    for epoch in range(epochs):\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((batch_size, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((batch_size, 1)))\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "        if epoch % save_interval == 0:\n",
        "            st.write(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}] [G loss: {g_loss}]\")\n",
        "            save_imgs(epoch)"
      ],
      "metadata": {
        "id": "fmbGeJrWIBzt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    # Save the figure\n",
        "    img_path = f\"generated_images_epoch_{epoch}.png\"\n",
        "    plt.savefig(img_path)\n",
        "    plt.close()\n",
        "    st.image(img_path)\n",
        "\n",
        "def main():\n",
        "    st.title(\"MNIST GAN Generator\")\n",
        "    st.write(\"Generating handwritten digits using GAN\")\n",
        "\n",
        "    # Train the GAN\n",
        "    train(epochs=100, batch_size=32, save_interval=1000)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zk5W1QbIefD",
        "outputId": "22570fdb-f65c-44a0-be34-0133c799c7e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-01-31 16:28:25.083 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 443ms/step\n",
            "1/1 [==============================] - 0s 308ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 178ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 224ms/step\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 162ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 221ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "\n",
        "def main():\n",
        "  st.title('MNIST GAN Generator')\n",
        "  st.write('Mnist Generate')\n",
        "\n",
        "  num_images = st.number_input('Enter the number: ')\n",
        "  train(epochs = 100, batch_size = 32, save_interval = 1000)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqBl_l1kI6Fd",
        "outputId": "31f8f9e5-e03e-4e71-8128-e75d2b8abb09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 186ms/step\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "1/1 [==============================] - 0s 163ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 244ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 160ms/step\n",
            "1/1 [==============================] - 0s 166ms/step\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "1/1 [==============================] - 0s 212ms/step\n",
            "1/1 [==============================] - 0s 163ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "1/1 [==============================] - 0s 203ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 220ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9NclZV3iK4ML"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}